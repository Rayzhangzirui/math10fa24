{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e781d47d",
   "metadata": {},
   "source": [
    "# Lecture Week 2 Mon 10/7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0336c9b4",
   "metadata": {},
   "source": [
    "**Poll**\n",
    "\n",
    "Given input x in 1D, output y in 1D. If we use feature \n",
    "\n",
    "$[x, 2x, 2^2x,..., 2^kx]$ ..., how does the model performance changes as we increase k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472262df",
   "metadata": {},
   "source": [
    "**Poll**\n",
    "\n",
    "Given input x in 1D, output y in 1D. If we use feature \n",
    "\n",
    "$[x, 2x, 2^2x,..., 2^kx]$ ..., how does the model performance changes as we increase k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f1ba0-c228-4289-b8f7-c7a3a93ad301",
   "metadata": {},
   "source": [
    "# Colinearity \n",
    "\n",
    "If two variables are highly correlated, intuitively, we can say that they are measuring the same thing. In the context of linear regression, this is called multicollinearity.\n",
    "\n",
    "Suppose $Y = aX_1$ and $X_2 = bX_1$, then we can write $Y = \\beta_1 X_1 + \\beta_2 X_2$ for any $\\beta_1$  and $\\beta_2$ such that $\\beta_1 + b \\beta_2 = a$.\n",
    "\n",
    "We can see that the coefficients are not unique. \n",
    "\n",
    "This cause a few problems:\n",
    "\n",
    "1. **Interpretation**: it's difficult to interpret the coefficients. Originally, we would say that a one unit increase in $X_1$ would lead to a $\\beta_1$ increase in $Y$. But now, we can't say that, because we can't change $X_1$ without changing $X_2$.\n",
    "\n",
    "2. **Large Variance of the parameter**: Since there could be infinite solutions, there is no guarantee which one the solver will find. Therefore small changes in the data could lead to large changes in the coefficients.\n",
    "\n",
    "3. **Numerical Stability**: Sometimes the solver can't find the solution.\n",
    "\n",
    "However, this does not affect the prediction: even though the coefficients are not unique, the prediction will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "448ff9b1-e978-492f-b2a5-071855bf7791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.random.uniform(0,1,(100,1))\n",
    "\n",
    "# append collinear columns\n",
    "X = np.column_stack((X, X[:,0]*2))\n",
    "y = X[:,0] + np.random.randn(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3ca7ace-a5f4-4741-be7d-10a65462e5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.76211788, 1.52423577],\n",
       "       [0.5029594 , 1.0059188 ],\n",
       "       [0.52575871, 1.05151742],\n",
       "       [0.22006325, 0.44012649],\n",
       "       [0.81791763, 1.63583527],\n",
       "       [0.68107268, 1.36214535],\n",
       "       [0.4016557 , 0.8033114 ],\n",
       "       [0.36164756, 0.72329513],\n",
       "       [0.38081373, 0.76162746],\n",
       "       [0.43256595, 0.86513191],\n",
       "       [0.19213296, 0.38426592],\n",
       "       [0.5214522 , 1.0429044 ],\n",
       "       [0.06073058, 0.12146116],\n",
       "       [0.71085978, 1.42171955],\n",
       "       [0.93333873, 1.86667747],\n",
       "       [0.66158163, 1.32316325],\n",
       "       [0.11017665, 0.22035331],\n",
       "       [0.26035445, 0.52070891],\n",
       "       [0.03233723, 0.06467445],\n",
       "       [0.31478408, 0.62956816],\n",
       "       [0.7073091 , 1.4146182 ],\n",
       "       [0.37579514, 0.75159028],\n",
       "       [0.2337066 , 0.4674132 ],\n",
       "       [0.61645368, 1.23290736],\n",
       "       [0.14374096, 0.28748192],\n",
       "       [0.40109488, 0.80218975],\n",
       "       [0.97757554, 1.95515108],\n",
       "       [0.93754553, 1.87509107],\n",
       "       [0.88649598, 1.77299195],\n",
       "       [0.656356  , 1.31271199],\n",
       "       [0.29456178, 0.58912356],\n",
       "       [0.54653214, 1.09306427],\n",
       "       [0.88575411, 1.77150822],\n",
       "       [0.64577643, 1.29155287],\n",
       "       [0.73233848, 1.46467695],\n",
       "       [0.97338618, 1.94677235],\n",
       "       [0.21784033, 0.43568066],\n",
       "       [0.12753862, 0.25507724],\n",
       "       [0.88057366, 1.76114733],\n",
       "       [0.21193264, 0.42386528],\n",
       "       [0.76584372, 1.53168744],\n",
       "       [0.15445438, 0.30890876],\n",
       "       [0.18372064, 0.36744127],\n",
       "       [0.45499015, 0.9099803 ],\n",
       "       [0.28686581, 0.57373161],\n",
       "       [0.02735923, 0.05471846],\n",
       "       [0.68168096, 1.36336193],\n",
       "       [0.25343661, 0.50687323],\n",
       "       [0.62902947, 1.25805893],\n",
       "       [0.0994719 , 0.19894379],\n",
       "       [0.8068893 , 1.6137786 ],\n",
       "       [0.26150393, 0.52300785],\n",
       "       [0.87518049, 1.75036098],\n",
       "       [0.4258212 , 0.8516424 ],\n",
       "       [0.11328905, 0.2265781 ],\n",
       "       [0.72414744, 1.44829489],\n",
       "       [0.4268573 , 0.85371459],\n",
       "       [0.72540867, 1.45081734],\n",
       "       [0.15733763, 0.31467527],\n",
       "       [0.22652972, 0.45305945],\n",
       "       [0.31599226, 0.63198451],\n",
       "       [0.13382998, 0.26765996],\n",
       "       [0.72253241, 1.44506482],\n",
       "       [0.21027294, 0.42054588],\n",
       "       [0.47643918, 0.95287835],\n",
       "       [0.7884414 , 1.5768828 ],\n",
       "       [0.92632449, 1.85264898],\n",
       "       [0.58552151, 1.17104302],\n",
       "       [0.92485997, 1.84971995],\n",
       "       [0.34674351, 0.69348702],\n",
       "       [0.24289621, 0.48579241],\n",
       "       [0.8143314 , 1.62866281],\n",
       "       [0.5322099 , 1.0644198 ],\n",
       "       [0.0185913 , 0.0371826 ],\n",
       "       [0.85405815, 1.70811631],\n",
       "       [0.62833392, 1.25666783],\n",
       "       [0.03420048, 0.06840096],\n",
       "       [0.58953933, 1.17907866],\n",
       "       [0.39680704, 0.79361409],\n",
       "       [0.32960882, 0.65921764],\n",
       "       [0.83265308, 1.66530616],\n",
       "       [0.55970626, 1.11941253],\n",
       "       [0.88443868, 1.76887736],\n",
       "       [0.08663012, 0.17326025],\n",
       "       [0.74148545, 1.48297089],\n",
       "       [0.46302441, 0.92604883],\n",
       "       [0.29187956, 0.58375911],\n",
       "       [0.04093826, 0.08187651],\n",
       "       [0.46075901, 0.92151802],\n",
       "       [0.5707372 , 1.14147439],\n",
       "       [0.93271585, 1.86543169],\n",
       "       [0.17788948, 0.35577897],\n",
       "       [0.10478946, 0.20957892],\n",
       "       [0.21191987, 0.42383974],\n",
       "       [0.04990644, 0.09981288],\n",
       "       [0.98446704, 1.96893409],\n",
       "       [0.40056453, 0.80112907],\n",
       "       [0.42533359, 0.85066718],\n",
       "       [0.0809081 , 0.16181621],\n",
       "       [0.33114064, 0.66228127]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "635e674c-f5d1-4583-b2de-e4f3008c46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefs: [0.17213533 0.34427066], intercept: 0.036208338624087455, score: 0.04965689668987128\n",
      "coefs: [0.86067664], intercept: 0.03620833862408768, score: 0.04965689668987128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# regression with X0 and X1=2*X0\n",
    "lreg_sklearn = LinearRegression()\n",
    "lreg_sklearn.fit(X,y)\n",
    "score = lreg_sklearn.score(X,y)\n",
    "print(f'coefs: {lreg_sklearn.coef_}, intercept: {lreg_sklearn.intercept_}, score: {score}')\n",
    "\n",
    "\n",
    "# regression with X0\n",
    "lreg_sklearn.fit(X[:,0:1],y)\n",
    "score = lreg_sklearn.score(X[:,0:1],y)\n",
    "print(f'coefs: {lreg_sklearn.coef_}, intercept: {lreg_sklearn.intercept_}, score: {score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5853992d-6bb7-41d6-bc35-032dc87a0b63",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515dde62-18ba-44b5-8e59-11ae65a2988b",
   "metadata": {},
   "source": [
    "## Training, Validation, and Testing\n",
    "\n",
    "Note that we have the following separate goals:\n",
    "\n",
    "- **Model selection**: estimate the performance of different models in order to choose the best one.\n",
    "- **Model assessment**: after choosing the best model, estimate its prediction error on new data.\n",
    "\n",
    "If we have plenty of data, we can split it into three sets: training, validation, and test. \n",
    "\n",
    "The training set is used to fit the models. \n",
    "The validation set is used to estimate prediction error, which is used to select the model or tune the hyperparameters. In our example, this is the degree of the polynomial. Notice that in the process, the models \"see\" the validation set.\n",
    "The test set is used for assessment of the generalization error of the final chosen model. This set is never seen by the models. We should not go back and choose the model based on the test set performance.\n",
    "\n",
    "One common way of splitting the data is 60% training, 20% validation, and 20% test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabc8aee-b79d-400f-9fc4-eb0239630cdc",
   "metadata": {},
   "source": [
    "Sometimes people use \"validation\" and \"test\" interchangeably. This is fine if we are only doing only one of the tasks above (model selection or model assessment). However, if we are doing both, we should have two separate sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ca6c2-bd8c-4c76-8467-87e5af3032f6",
   "metadata": {},
   "source": [
    "## Question:\n",
    "\n",
    "Take the penguins dataset. Use the flipper length to predict the body mass. \n",
    "Perform a 5-fold cross-validation. What is the average mean squared error?\n",
    "\n",
    "Feel free Look up the documentation of KFold, google, chatGPT, or discuss with your classmates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbfb011b-4147-4dbc-96aa-9f243db747a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from scikit-learn\n",
    "# https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.KFold.html\n",
    "from sklearn.model_selection import KFold\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7ce801b-99c6-4f0c-886a-90c122e0d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef373716-2098-402b-b3be-2e255d59f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._split.KFold"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kf)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1811d780-82f3-47e0-8c8f-d0962cf749fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(kf.split(X))\n",
    "# This is an object that is similar to the range object\n",
    "# We can iterate over it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372a9147-3f12-4a24-bea4-f33cae0bace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: index=[1 2 3]\n",
      "  Test:  index=[0]\n",
      "  Train: index=[0 2 3]\n",
      "  Test:  index=[1]\n",
      "  Train: index=[0 1 3]\n",
      "  Test:  index=[2]\n",
      "  Train: index=[0 1 2]\n",
      "  Test:  index=[3]\n"
     ]
    }
   ],
   "source": [
    "# get the indices of the train and test sets\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1777e692-1cc4-43e1-88d8-4f18460b5c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  i: 0\n",
      "  Train: index=[1 2 3]\n",
      "  Test:  index=[0]\n",
      "  i: 1\n",
      "  Train: index=[0 2 3]\n",
      "  Test:  index=[1]\n",
      "  i: 2\n",
      "  Train: index=[0 1 3]\n",
      "  Test:  index=[2]\n",
      "  i: 3\n",
      "  Train: index=[0 1 2]\n",
      "  Test:  index=[3]\n"
     ]
    }
   ],
   "source": [
    "# using enumerate to get the index of the fold\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(f\"  i: {i}\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc16eb9e-345f-482a-86e1-bb12e6da99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 R^2 score: 0.725084353204537\n",
      "Fold 1 R^2 score: 0.6993225273807326\n",
      "Fold 2 R^2 score: 0.7895360534716703\n",
      "Fold 3 R^2 score: 0.7782229609972658\n",
      "Fold 4 R^2 score: 0.794602971686194\n",
      "Mean R^2 score: 0.75735377334808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Load the Penguins dataset\n",
    "df = sns.load_dataset('penguins')\n",
    "df.dropna(inplace=True)  # Remove missing values\n",
    "\n",
    "# features = ['bill_length_mm', 'bill_depth_mm','flipper_length_mm']\n",
    "features = ['flipper_length_mm']\n",
    "target = ['body_mass_g']  \n",
    "\n",
    "# Initialize linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df)):\n",
    "    X_train = df[features].iloc[train_index] \n",
    "    X_test  = df[features].iloc[test_index]\n",
    "\n",
    "    y_train = df[target].iloc[train_index]\n",
    "    y_test = df[target].iloc[test_index]\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    all_scores.append(score)\n",
    "\n",
    "    print(f\"Fold {i} R^2 score:\", score)\n",
    "\n",
    "print(f\"Mean R^2 score: {np.mean(all_scores)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
