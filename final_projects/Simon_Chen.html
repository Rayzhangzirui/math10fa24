
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Medical Insurance Prediction &#8212; UCI Math 10, Fall 2024</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'final_projects/Simon_Chen';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Prediction of High School Students’ Academic Performance" href="Zhang_Zhang.html" />
    <link rel="prev" title="Predicting Subscription to Term Deposit" href="Pinge_Chen.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
  
    <p class="title logo__title">UCI Math 10, Fall 2024</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    UC Irvine, Math 10, Fall 2024
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../syllabus.html">Course Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../final_project_instruction.html">Final Project Instruction</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../notes/notes_intro.html">Notes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../notes/python_review.html">Python review</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notes/OOP.html">Object-Oriented Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/numpy.html">NumPy Review</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/prob_stat.html">Probability and Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/pandas.html">Pandas dataframe</a></li>





<li class="toctree-l2"><a class="reference internal" href="../notes/visualization.html">Visualization</a></li>


<li class="toctree-l2"><a class="reference internal" href="../notes/linear_regression.html">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/multi_linear_reg.html">Multiple Linear Regression</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notes/polynomial_reg.html">Polynomial Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/bias_variance.html">Bias-Variance Tradeoff</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notes/cv.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/feature_scaling.html">Feature Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/regularization.html">Regularization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/gradient_descent.html">Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/logistic_binary.html">Binary Classification with logistic regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/logistic_multiclass.html">Logistic Regression for Multiclass Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/fairness.html">Bias and Fairness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/knn.html">Nearest Neighbor Regression and Classification</a></li>

<li class="toctree-l2"><a class="reference internal" href="../notes/kmeans.html">Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/pca.html">Dimensionality Reduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/intro_nn.html">Nerual Network</a></li>
<li class="toctree-l2"><a class="reference internal" href="../notes/gan.html">Generative Models</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../lecture/intro.html">Lectures</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week1_Mon.html">Lecture Week 1 Mon 9/30</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week1_Wed.html">Lecture Week 1 Wed 10/2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week1_Fri.html">Lecture Week 1 Fri 10/4</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week2_Mon.html">Lecture Week 2 Mon 10/7</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week2_Wed.html">Lecture Week 2 Wed 10/9</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week2_Fri.html">Lecture Week 2 Fri 10/11</a></li>

<li class="toctree-l2"><a class="reference internal" href="../lecture/week3_Mon.html">Lecture Week 3 Mon 10/14</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week3_Wed.html">Lecture Week 3 Wed 10/16</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week3_Fri.html">Lecture Week 3 Fri 10/19</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week4_Mon.html">Lecture Week 4 Mon 10/21</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week4_Wed.html">Lecture Week 4 Wed 10/23</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week4_Fri.html">Lecture Week 4 Fri 10/25</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week5_Mon.html">Lecture Week 5 Mon 10/7</a></li>


<li class="toctree-l2"><a class="reference internal" href="../lecture/week5_Wed.html">Lecture Week 5 Wed 10/30</a></li>



<li class="toctree-l2"><a class="reference internal" href="../lecture/week5_Fri.html">Lecture Week 5 Fri 11/1</a></li>

<li class="toctree-l2"><a class="reference internal" href="../lecture/week6_Wed.html">Lecture Week 6 Wed 11/6</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week6_Fri.html">Lecture Week 6 Fri 11/8</a></li>

<li class="toctree-l2"><a class="reference internal" href="../lecture/week7_Wed.html">Lecture Week 7 Wed 11/13</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week7_Fri.html">Lecture Week 7 Fri 11/15</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week8_Mon.html">Lecture Week 8 Mon 11/18</a></li>
<li class="toctree-l2"><a class="reference internal" href="../lecture/week8_Wed.html">Lecture Week 8 Wed 11/20</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../homework/intro.html">Homework</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw1.html">Homework 1 (Due 10/4/2024 at 11:59pm)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw2_sol.html">Homework 2 (Due 10/11/2024 at 11:59pm)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw3_sol.html">Homework 3 (Due 10/18/2024 at 11:59pm)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw4_sol.html">Homework 4 (Due 10/25/2024 at 11:59pm)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw5_sol.html">Homework 5 (Due 11/1/2024 at 11:59pm)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw6_sol.html">Homework 6 (Due 11/15/2024 at 11:59pm)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/hw7_sol.html">Homework 7 (Due 11/25/2024 at 11:59pm)</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Student Projects</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Caroline_Cheng.html">Ballon D’or winner prediction model</a></li>
<li class="toctree-l2"><a class="reference internal" href="Davin_Huynh.html">Predicting Heart Disease with Standard Machine Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="Gabriela_Zuno.html">Correlation Bewteen a T.V Show’s Genre and Queer Female Character Deaths</a></li>











<li class="toctree-l2"><a class="reference internal" href="Hailili_Subinuer.html">The Application of Machine Learning in Gold Price Prediction</a></li>

<li class="toctree-l2"><a class="reference internal" href="Helena_Tran.html">Analyzing Life Expectancy Across Countries</a></li>








<li class="toctree-l2"><a class="reference internal" href="James_Cho.html">TQQQ Stock Predictor Project</a></li>
<li class="toctree-l2"><a class="reference internal" href="Kaiyuan_Chen.html">Data analysis of new energy vehicles in China</a></li>
<li class="toctree-l2"><a class="reference internal" href="Kent_Hocaoglu.html">Analysis of Crime Reports in LA</a></li>
<li class="toctree-l2"><a class="reference internal" href="Krishna_Saraogi.html">Step 1: Data Exploration/ Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nguyen_Bui.html">Title: Should I investing to SIRI stock ? Reason?</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nicholas_Le.html">Predicting Student Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nikolina_Sentovich.html">An Analysis on the Likeliness of People Changing Their Occupation</a></li>

<li class="toctree-l2"><a class="reference internal" href="Pinge_Chen.html">Predicting Subscription to Term Deposit</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Medical Insurance Prediction</a></li>

<li class="toctree-l2"><a class="reference internal" href="Zhang_Zhang.html">Prediction of High School Students’ Academic Performance</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/final_projects/Simon_Chen.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Medical Insurance Prediction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Medical Insurance Prediction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#import-libraries">0. Import Libraries</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-the-dataset">1. Introduction to the Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">2. Data Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-code-below-provides-information-about-the-dataset-key-points-to-note-include">The code below provides information about the dataset. Key points to note include:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling">Feature Scaling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploratory-data-analysis">3. Exploratory Data Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-observations">Some observations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#from-the-correlation-heatmap-we-can-observe-that-the-most-valuable-insights-come-from-the-last-row-which-shows-the-correlation-between-premium-price-and-other-features-the-correlation-between-age-and-premium-price-has-the-highest-value-which-is-expected-the-next-most-correlated-feature-is-the-number-of-major-surgeries-with-a-correlation-of-0-43-based-on-these-statistics-we-can-create-a-subset-of-features-to-train-the-models">From the correlation heatmap, we can observe that the most valuable insights come from the last row, which shows the correlation between Premium Price and other features. The correlation between Age and Premium Price has the highest value, which is expected. The next most correlated feature is the Number of Major Surgeries, with a correlation of <strong>0.43</strong>. Based on these statistics, we can create a subset of features to train the models.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">4. Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-model">(1). Linear Regression Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#from-the-result-we-can-see-the-average-r-2-with-5-fold-cross-validation-is-around-0-62">From the result, we can see the average <span class="math notranslate nohighlight">\(R^2\)</span> with 5-fold cross-validation is around <strong>0.62</strong>.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression-model">(2). Polynomial Regression Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-highest-r-2-with-cross-validation-is-degree-of-2-polynomial-with-r-2-of-0-67-other-degrees-are-really-off">The highest <span class="math notranslate nohighlight">\(R^2\)</span> with cross-validation is degree of 2 polynomial, with R^2 of <strong>0.67</strong>. Other degrees are really off.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection-for-the-next-two-models">Feature Selection for the Next Two Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-selected-features">(3). Linear Regression with Selected Features</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-score-is-0-49-which-is-lower-than-that-of-linear-regression-without-the-selected-features-this-indicates-that-the-features-i-selected-do-not-improve-the-performance-of-the-linear-regression-model">The <span class="math notranslate nohighlight">\(R^2\)</span> score is <strong>0.49</strong>, which is lower than that of Linear Regression without the selected features. This indicates that the features I selected do not improve the performance of the Linear Regression model.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression-with-selected-features">(4). Polynomial Regression with Selected Features</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-result-of-the-polynomial-regression-is-similar-and-does-not-improve-upon-the-original-polynomial-regression-model">The result of the polynomial regression is similar and does not improve upon the original polynomial regression model.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#models-with-regularization">(5). Models with Regularization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#since-the-models-with-selected-features-failed-to-provide-better-performance-i-will-try-using-ridge-regularization-to-identify-which-features-contribute-to-improving-predictions">Since the models with selected features failed to provide better performance, I will try using Ridge regularization to identify which features contribute to improving predictions.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#in-addition-to-plotting-the-ridge-regularization-i-also-included-an-extra-model-ridge-regression-although-we-did-not-cover-it-i-believe-it-will-be-useful-for-comparison">In addition to plotting the Ridge regularization, I also included an extra model: Ridge Regression. Although we did not cover it, I believe it will be useful for comparison.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-of-ridge-regression-is-0-62-which-is-same-as-the-original-linear-regression-model">The <span class="math notranslate nohighlight">\(R^2\)</span> of Ridge Regression is <strong>0.62</strong>, which is same as the original Linear Regression model.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#new-selected-features">New selected features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-features-from-regularization-better-features">(6). Linear Regression with features from regularization (better features).</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-did-not-improve-significantly-compared-to-the-original-model-but-it-is-better-than-the-model-with-the-originally-selected-features">The <span class="math notranslate nohighlight">\(R^2\)</span> did not improve significantly compared to the original model, but it is better than the model with the originally selected features.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression-with-features-from-regularization-better-features">(7). Polynomial Regression with features from regularization (better features).</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#so-far-this-model-gives-the-highest-performance-which-r-2-of-0-67">So far this model gives the highest performance, which <span class="math notranslate nohighlight">\(R^2\)</span> of <strong>0.67</strong>.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extras">4.5 Extras</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#in-this-section-i-will-introduce-a-few-additional-models-that-were-not-covered-in-our-class-these-models-all-demonstrate-good-performance">In this section, I will introduce a few additional models that were not covered in our class. These models all demonstrate good performance.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-model">(8). Random Forest Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-of-this-model-is-0-79">The <span class="math notranslate nohighlight">\(R^2\)</span> of this model is <strong>0.79</strong>.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">(9). Gradient Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#although-gradient-boosting-did-not-achieve-a-higher-r-2-than-random-forest-it-still-outperforms-the-standard-regression-models">Although Gradient Boosting did not achieve a higher <span class="math notranslate nohighlight">\(R^2\)</span> than Random Forest, it still outperforms the standard regression models.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hist-gradient-boosting">(10). Hist Gradient Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-is-higher-than-gradient-boosting">The <span class="math notranslate nohighlight">\(R^2\)</span> is higher than Gradient Boosting.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking-regressor">(11). Stacking Regressor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking-regressor-gives-the-best-performance-with-r-2-of-0-8">Stacking Regressor gives the best performance, with <span class="math notranslate nohighlight">\(R^2\)</span> of <strong>0.8</strong>.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">5. Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-comparing">Performance Comparing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#from-the-histogram-plot-we-can-observe-a-clearer-representation-of-prediction-performance-the-additional-models-show-similar-results-while-the-other-models-perform-adequately-among-all-the-models-discussed-in-our-lecture-polynomial-regression-models-of-degree-2-provide-the-best-predictions-both-with-and-without-the-selected-features">From the histogram plot, we can observe a clearer representation of prediction performance. The additional models show similar results, while the other models perform adequately. Among all the models discussed in our lecture, polynomial regression models of degree 2 provide the best predictions, both with and without the selected features.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-regular-and-advanced-models">Comparing Regular and Advanced Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-methods-the-power-behind-advanced-models">Ensemble Methods: The Power Behind Advanced Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">Stacking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">6. Conclusion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#this-project-focused-on-a-few-key-steps">This project focused on a few key steps:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#future-improvements">Future Improvements:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-final-thoughts">Some final thoughts:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">7. References</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="medical-insurance-prediction">
<h1>Medical Insurance Prediction<a class="headerlink" href="#medical-insurance-prediction" title="Link to this heading">#</a></h1>
<p>Author: Simon Chen</p>
<p>Course Project, UC Irvine, Math 10, Fall 24</p>
<p>I would like to post my notebook on the course’s website.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="import-libraries">
<h1>0. Import Libraries<a class="headerlink" href="#import-libraries" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Preprocessing and Feature Engineering</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">PolynomialFeatures</span><span class="p">,</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="c1"># Data Manipulation and Visualization</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">matplotlib.gridspec</span> <span class="k">as</span> <span class="nn">gridspec</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Model Selection and Evaluation</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># Models and Algorithms</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">LinearRegression</span><span class="p">,</span>
    <span class="n">LogisticRegression</span><span class="p">,</span>
    <span class="n">Ridge</span><span class="p">,</span>
    <span class="n">Lasso</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">RandomForestRegressor</span><span class="p">,</span>
    <span class="n">GradientBoostingRegressor</span><span class="p">,</span>
    <span class="n">HistGradientBoostingRegressor</span><span class="p">,</span>
    <span class="n">StackingRegressor</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPRegressor</span>

<span class="c1"># Other Utilities</span>
<span class="kn">from</span> <span class="nn">statsmodels.stats.outliers_influence</span> <span class="kn">import</span> <span class="n">variance_inflation_factor</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>
</pre></div>
</div>
</div>
</div>
<section id="introduction-to-the-dataset">
<h2>1. Introduction to the Dataset<a class="headerlink" href="#introduction-to-the-dataset" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">Medi.csv</span></code> dataset consists of various features that can be used to predict insurance premium prices. Below is a brief description of each feature:</p>
<ul class="simple">
<li><p><strong>Age</strong>: The age of the insured individual.</p></li>
<li><p><strong>Diabetes</strong>: Indicates whether the individual has diabetes (1 for Yes, 0 for No).</p></li>
<li><p><strong>BloodPressureProblems</strong>: Indicates if the individual has blood pressure issues (1 for Yes, 0 for No).</p></li>
<li><p><strong>AnyTransplants</strong>: Indicates if the individual has undergone any transplants (1 for Yes, 0 for No).</p></li>
<li><p><strong>AnyChronicDiseases</strong>: Indicates if the individual has any chronic diseases (1 for Yes, 0 for No).</p></li>
<li><p><strong>Height</strong>: Height of the individual (in centimeters).</p></li>
<li><p><strong>Weight</strong>: Weight of the individual (in kilograms).</p></li>
<li><p><strong>KnownAllergies</strong>: Indicates if the individual has known allergies (1 for Yes, 0 for No).</p></li>
<li><p><strong>HistoryOfCancerInFamily</strong>: Indicates if there is a family history of cancer (1 for Yes, 0 for No).</p></li>
<li><p><strong>NumberOfMajorSurgeries</strong>: The number of major surgeries the individual has undergone.</p></li>
<li><p><strong>PremiumPrice</strong>: The target variable representing the insurance premium price.</p></li>
</ul>
<p>We use these features to build a model that can predict the <strong>PremiumPrice</strong> for an individual based on their health and demographic information. By understanding and analyzing these features, we can gain insights into the factors that most significantly affect insurance costs, helping insurance companies set fair and accurate pricing.</p>
</section>
<section id="data-preprocessing">
<h2>2. Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Link to this heading">#</a></h2>
<section id="the-code-below-provides-information-about-the-dataset-key-points-to-note-include">
<h3>The code below provides information about the dataset. Key points to note include:<a class="headerlink" href="#the-code-below-provides-information-about-the-dataset-key-points-to-note-include" title="Link to this heading">#</a></h3>
<ul>
<li><h4 class="rubric" id="the-dataset-contains-986-samples">The dataset contains 986 samples.</h4>
</li>
<li><h4 class="rubric" id="no-missing-data-is-present">No missing data is present.</h4>
</li>
<li><h4 class="rubric" id="each-feature-is-of-the-int64-data-type-with-some-being-categorical-and-others-numerical">Each feature is of the int64 data type, with some being categorical and others numerical.</h4>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Medi.csv&#39;</span><span class="p">,</span> <span class="n">thousands</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   Age  Diabetes  BloodPressureProblems  AnyTransplants  AnyChronicDiseases  \
0   45         0                      0               0                   0   
1   60         1                      0               0                   0   
2   36         1                      1               0                   0   
3   52         1                      1               0                   1   
4   38         0                      0               0                   1   

   Height  Weight  KnownAllergies  HistoryOfCancerInFamily  \
0     155      57               0                        0   
1     180      73               0                        0   
2     158      59               0                        0   
3     183      93               0                        0   
4     166      88               0                        0   

   NumberOfMajorSurgeries  PremiumPrice  
0                       0         25000  
1                       0         29000  
2                       1         23000  
3                       2         28000  
4                       1         23000  
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 986 entries, 0 to 985
Data columns (total 11 columns):
 #   Column                   Non-Null Count  Dtype
---  ------                   --------------  -----
 0   Age                      986 non-null    int64
 1   Diabetes                 986 non-null    int64
 2   BloodPressureProblems    986 non-null    int64
 3   AnyTransplants           986 non-null    int64
 4   AnyChronicDiseases       986 non-null    int64
 5   Height                   986 non-null    int64
 6   Weight                   986 non-null    int64
 7   KnownAllergies           986 non-null    int64
 8   HistoryOfCancerInFamily  986 non-null    int64
 9   NumberOfMajorSurgeries   986 non-null    int64
 10  PremiumPrice             986 non-null    int64
dtypes: int64(11)
memory usage: 84.9 KB
None
              Age    Diabetes  BloodPressureProblems  AnyTransplants  \
count  986.000000  986.000000             986.000000      986.000000   
mean    41.745436    0.419878               0.468560        0.055781   
std     13.963371    0.493789               0.499264        0.229615   
min     18.000000    0.000000               0.000000        0.000000   
25%     30.000000    0.000000               0.000000        0.000000   
50%     42.000000    0.000000               0.000000        0.000000   
75%     53.000000    1.000000               1.000000        0.000000   
max     66.000000    1.000000               1.000000        1.000000   

       AnyChronicDiseases      Height      Weight  KnownAllergies  \
count          986.000000  986.000000  986.000000      986.000000   
mean             0.180527  168.182556   76.950304        0.215010   
std              0.384821   10.098155   14.265096        0.411038   
min              0.000000  145.000000   51.000000        0.000000   
25%              0.000000  161.000000   67.000000        0.000000   
50%              0.000000  168.000000   75.000000        0.000000   
75%              0.000000  176.000000   87.000000        0.000000   
max              1.000000  188.000000  132.000000        1.000000   

       HistoryOfCancerInFamily  NumberOfMajorSurgeries  PremiumPrice  
count               986.000000              986.000000    986.000000  
mean                  0.117647                0.667343  24336.713996  
std                   0.322353                0.749205   6248.184382  
min                   0.000000                0.000000  15000.000000  
25%                   0.000000                0.000000  21000.000000  
50%                   0.000000                1.000000  23000.000000  
75%                   0.000000                1.000000  28000.000000  
max                   1.000000                3.000000  40000.000000  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
<span class="c1"># we can see there is no missing data.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Age                        0
Diabetes                   0
BloodPressureProblems      0
AnyTransplants             0
AnyChronicDiseases         0
Height                     0
Weight                     0
KnownAllergies             0
HistoryOfCancerInFamily    0
NumberOfMajorSurgeries     0
PremiumPrice               0
dtype: int64
</pre></div>
</div>
</div>
</div>
<section id="feature-scaling">
<h4>Feature Scaling<a class="headerlink" href="#feature-scaling" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># I choose standardization as scaling method.</span>
<span class="c1"># I only scale numerical features.</span>
<span class="n">numerical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;Height&#39;</span><span class="p">,</span> <span class="s1">&#39;Weight&#39;</span><span class="p">,</span> <span class="s1">&#39;NumberOfMajorSurgeries&#39;</span><span class="p">]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="n">numerical_features</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">numerical_features</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>        Age  Diabetes  BloodPressureProblems  AnyTransplants  \
0  0.233197         0                      0               0   
1  1.307981         1                      0               0   
2 -0.411674         1                      1               0   
3  0.734763         1                      1               0   
4 -0.268369         0                      0               0   

   AnyChronicDiseases    Height    Weight  KnownAllergies  \
0                   0 -1.306105 -1.399250               0   
1                   0  1.170852 -0.277062               0   
2                   0 -1.008870 -1.258976               0   
3                   1  1.468086  1.125674               0   
4                   1 -0.216244  0.774990               0   

   HistoryOfCancerInFamily  NumberOfMajorSurgeries  PremiumPrice  
0                        0               -0.891187         25000  
1                        0               -0.891187         29000  
2                        0                0.444239         23000  
3                        0                1.779665         28000  
4                        0                0.444239         23000  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># data visualization, with help from ChatGPT.</span>
<span class="n">num_columns</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">num_rows</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_columns</span> <span class="o">+</span> <span class="mi">3</span><span class="p">)</span> <span class="o">//</span> <span class="mi">4</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">num_rows</span><span class="p">))</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">gridspec</span><span class="o">.</span><span class="n">GridSpec</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">figure</span><span class="o">=</span><span class="n">fig</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">gs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Histogram of </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f5fa64ecb6cdcd72d6103fd367d376bc1ec510b76a1d7494663fd090e04904b1.png" src="../_images/f5fa64ecb6cdcd72d6103fd367d376bc1ec510b76a1d7494663fd090e04904b1.png" />
</div>
</div>
</section>
</section>
</section>
<section id="exploratory-data-analysis">
<h2>3. Exploratory Data Analysis<a class="headerlink" href="#exploratory-data-analysis" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Correlation Heatmap</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Feature Correlation Heatmap&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Pairplot to Visualize Relationships Between Features</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Summary Statistics</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Summary Statistics:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/300494d9bb51373166828733d7589ef042e899544897b684051e66d83f1c9242.png" src="../_images/300494d9bb51373166828733d7589ef042e899544897b684051e66d83f1c9242.png" />
<img alt="../_images/18762d0be8e130abfb514847901734e8218d1a9b9ee98beeed6a4ded95c7466e.png" src="../_images/18762d0be8e130abfb514847901734e8218d1a9b9ee98beeed6a4ded95c7466e.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Summary Statistics:

                Age    Diabetes  BloodPressureProblems  AnyTransplants  \
count  9.860000e+02  986.000000             986.000000      986.000000   
mean   1.945705e-16    0.419878               0.468560        0.055781   
std    1.000507e+00    0.493789               0.499264        0.229615   
min   -1.701415e+00    0.000000               0.000000        0.000000   
25%   -8.415874e-01    0.000000               0.000000        0.000000   
50%    1.824009e-02    0.000000               0.000000        0.000000   
75%    8.064152e-01    1.000000               1.000000        0.000000   
max    1.737895e+00    1.000000               1.000000        1.000000   

       AnyChronicDiseases        Height        Weight  KnownAllergies  \
count          986.000000  9.860000e+02  9.860000e+02      986.000000   
mean             0.180527  4.900295e-16 -1.369200e-16        0.215010   
std              0.384821  1.000507e+00  1.000507e+00        0.411038   
min              0.000000 -2.296887e+00 -1.820070e+00        0.000000   
25%              0.000000 -7.116350e-01 -6.978820e-01        0.000000   
50%              0.000000 -1.808731e-02 -1.367880e-01        0.000000   
75%              0.000000  7.745387e-01  7.048530e-01        0.000000   
max              1.000000  1.963478e+00  3.861007e+00        1.000000   

       HistoryOfCancerInFamily  NumberOfMajorSurgeries  PremiumPrice  
count               986.000000            9.860000e+02    986.000000  
mean                  0.117647            1.801579e-17  24336.713996  
std                   0.322353            1.000507e+00   6248.184382  
min                   0.000000           -8.911867e-01  15000.000000  
25%                   0.000000           -8.911867e-01  21000.000000  
50%                   0.000000            4.442389e-01  23000.000000  
75%                   0.000000            4.442389e-01  28000.000000  
max                   1.000000            3.115090e+00  40000.000000  
</pre></div>
</div>
</div>
</div>
<section id="some-observations">
<h3>Some observations<a class="headerlink" href="#some-observations" title="Link to this heading">#</a></h3>
<section id="from-the-correlation-heatmap-we-can-observe-that-the-most-valuable-insights-come-from-the-last-row-which-shows-the-correlation-between-premium-price-and-other-features-the-correlation-between-age-and-premium-price-has-the-highest-value-which-is-expected-the-next-most-correlated-feature-is-the-number-of-major-surgeries-with-a-correlation-of-0-43-based-on-these-statistics-we-can-create-a-subset-of-features-to-train-the-models">
<h4>From the correlation heatmap, we can observe that the most valuable insights come from the last row, which shows the correlation between Premium Price and other features. The correlation between Age and Premium Price has the highest value, which is expected. The next most correlated feature is the Number of Major Surgeries, with a correlation of <strong>0.43</strong>. Based on these statistics, we can create a subset of features to train the models.<a class="headerlink" href="#from-the-correlation-heatmap-we-can-observe-that-the-most-valuable-insights-come-from-the-last-row-which-shows-the-correlation-between-premium-price-and-other-features-the-correlation-between-age-and-premium-price-has-the-highest-value-which-is-expected-the-next-most-correlated-feature-is-the-number-of-major-surgeries-with-a-correlation-of-0-43-based-on-these-statistics-we-can-create-a-subset-of-features-to-train-the-models" title="Link to this heading">#</a></h4>
</section>
</section>
</section>
<section id="model-selection">
<h2>4. Model Selection<a class="headerlink" href="#model-selection" title="Link to this heading">#</a></h2>
<section id="linear-regression-model">
<h3>(1). Linear Regression Model<a class="headerlink" href="#linear-regression-model" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;PremiumPrice&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;PremiumPrice&#39;</span><span class="p">]</span>

<span class="c1"># Split </span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">linear_regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># I am going to use 5-fold cross-validation</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">r2_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    
    <span class="n">linear_regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
    <span class="n">y_pred_fold</span> <span class="o">=</span> <span class="n">linear_regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_fold</span><span class="p">)</span>
    <span class="n">r2_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>

<span class="n">average_r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">r2_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average Linear Regression R^2 score: </span><span class="si">{</span><span class="n">average_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Linear Regression R^2 score: 0.62
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting R² scores for Linear Regression</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">r2_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">average_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">average_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Linear Regression&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e7397dcd9d61f603e1b27e9d1272dcde70fd66c61feae6b7c21da7912cce13ee.png" src="../_images/e7397dcd9d61f603e1b27e9d1272dcde70fd66c61feae6b7c21da7912cce13ee.png" />
</div>
</div>
<section id="from-the-result-we-can-see-the-average-r-2-with-5-fold-cross-validation-is-around-0-62">
<h4>From the result, we can see the average <span class="math notranslate nohighlight">\(R^2\)</span> with 5-fold cross-validation is around <strong>0.62</strong>.<a class="headerlink" href="#from-the-result-we-can-see-the-average-r-2-with-5-fold-cross-validation-is-around-0-62" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="polynomial-regression-model">
<h3>(2). Polynomial Regression Model<a class="headerlink" href="#polynomial-regression-model" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Polynomial Regression (All Features)</span>
<span class="n">max_degree</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">best_degree</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">best_r2</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
    <span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">scores_poly</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
    <span class="n">avg_r2_poly</span> <span class="o">=</span> <span class="n">scores_poly</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Polynomial Degree </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1"> Average R^2 score: </span><span class="si">{</span><span class="n">avg_r2_poly</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">avg_r2_poly</span> <span class="o">&gt;</span> <span class="n">best_r2</span><span class="p">:</span>
        <span class="n">best_r2</span> <span class="o">=</span> <span class="n">avg_r2_poly</span>
        <span class="n">best_degree</span> <span class="o">=</span> <span class="n">degree</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Best polynomial degree (All Features): </span><span class="si">{</span><span class="n">best_degree</span><span class="si">}</span><span class="s1"> with R^2: </span><span class="si">{</span><span class="n">best_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Polynomial Degree 1 Average R^2 score: 0.62
Polynomial Degree 2 Average R^2 score: 0.67
Polynomial Degree 3 Average R^2 score: -117379802002969648.00
Polynomial Degree 4 Average R^2 score: -6790995910801204707328.00
Polynomial Degree 5 Average R^2 score: -63.55
Best polynomial degree (All Features): 2 with R^2: 0.67
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate R^2 scores for polynomial degree 2 across folds for all features</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">r2_scores_poly_degree_2</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores_poly_degree_2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">r2_scores_poly_degree_2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">r2_scores_poly_degree_2</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">r2_scores_poly_degree_2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Polynomial Degree 2 (All Features)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores_poly_degree_2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/dbf63634b6c9feef6f4992e0c9a89a14148d432a1a74cb212279c7fc605a6460.png" src="../_images/dbf63634b6c9feef6f4992e0c9a89a14148d432a1a74cb212279c7fc605a6460.png" />
</div>
</div>
<section id="the-highest-r-2-with-cross-validation-is-degree-of-2-polynomial-with-r-2-of-0-67-other-degrees-are-really-off">
<h4>The highest <span class="math notranslate nohighlight">\(R^2\)</span> with cross-validation is degree of 2 polynomial, with R^2 of <strong>0.67</strong>. Other degrees are really off.<a class="headerlink" href="#the-highest-r-2-with-cross-validation-is-degree-of-2-polynomial-with-r-2-of-0-67-other-degrees-are-really-off" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="feature-selection-for-the-next-two-models">
<h3>Feature Selection for the Next Two Models<a class="headerlink" href="#feature-selection-for-the-next-two-models" title="Link to this heading">#</a></h3>
<p>In the following models, I have selected the features:</p>
<ul class="simple">
<li><p><strong>Age</strong></p></li>
<li><p><strong>Number of Major Surgeries</strong></p></li>
<li><p><strong>Diabetes</strong></p></li>
<li><p><strong>Blood Pressure Problems</strong></p></li>
</ul>
<p>These features were chosen based on correlation analysis, as they showed a higher correlation with the target variable, <strong>Premium Price</strong>. By focusing on these features, the models might potentially achieve better predictive performance while reducing complexity.</p>
</section>
<section id="linear-regression-with-selected-features">
<h3>(3). Linear Regression with Selected Features<a class="headerlink" href="#linear-regression-with-selected-features" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Linear Regression with Selected Features</span>
<span class="n">selected_features_1</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;NumberOfMajorSurgeries&#39;</span><span class="p">,</span> <span class="s1">&#39;Diabetes&#39;</span><span class="p">,</span> <span class="s1">&#39;BloodPressureProblems&#39;</span><span class="p">]</span>
<span class="n">X_selected_1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">selected_features_1</span><span class="p">]</span>
<span class="n">linear_regression_selected_1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores_selected_1</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression_selected_1</span><span class="p">,</span> <span class="n">X_selected_1</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="n">average_selected_1_r2</span> <span class="o">=</span> <span class="n">scores_selected_1</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average R² (Selected Features Model 1): </span><span class="si">{</span><span class="n">average_selected_1_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average R² (Selected Features Model 1): 0.49
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting R² scores for Selected Features Model 1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_selected_1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">scores_selected_1</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">average_selected_1_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">average_selected_1_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Selected Features Model 1&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_selected_1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/d32e442371057cf6a5993acc51bff76f0bcd841336f2e00c76efa6497fd8576a.png" src="../_images/d32e442371057cf6a5993acc51bff76f0bcd841336f2e00c76efa6497fd8576a.png" />
</div>
</div>
<section id="the-r-2-score-is-0-49-which-is-lower-than-that-of-linear-regression-without-the-selected-features-this-indicates-that-the-features-i-selected-do-not-improve-the-performance-of-the-linear-regression-model">
<h4>The <span class="math notranslate nohighlight">\(R^2\)</span> score is <strong>0.49</strong>, which is lower than that of Linear Regression without the selected features. This indicates that the features I selected do not improve the performance of the Linear Regression model.<a class="headerlink" href="#the-r-2-score-is-0-49-which-is-lower-than-that-of-linear-regression-without-the-selected-features-this-indicates-that-the-features-i-selected-do-not-improve-the-performance-of-the-linear-regression-model" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="polynomial-regression-with-selected-features">
<h3>(4). Polynomial Regression with Selected Features<a class="headerlink" href="#polynomial-regression-with-selected-features" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Polynomial Regression (Selected Features)</span>
<span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;NumberOfMajorSurgeries&#39;</span><span class="p">,</span> <span class="s1">&#39;Diabetes&#39;</span><span class="p">,</span> <span class="s1">&#39;BloodPressureProblems&#39;</span><span class="p">]</span>
<span class="n">X_selected</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>

<span class="n">best_selected_degree</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">best_selected_r22</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
    <span class="n">X_selected_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_selected</span><span class="p">)</span>
    <span class="n">scores_selected_poly</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_selected_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
    <span class="n">avg_selected_r2</span> <span class="o">=</span> <span class="n">scores_selected_poly</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Selected Features Polynomial Degree </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1"> Average R^2 score: </span><span class="si">{</span><span class="n">avg_selected_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">avg_selected_r2</span> <span class="o">&gt;</span> <span class="n">best_selected_r22</span><span class="p">:</span>
        <span class="n">best_selected_r22</span> <span class="o">=</span> <span class="n">avg_selected_r2</span>
        <span class="n">best_selected_degree</span> <span class="o">=</span> <span class="n">degree</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Best polynomial degree (Selected Features): </span><span class="si">{</span><span class="n">best_selected_degree</span><span class="si">}</span><span class="s1"> with R^2: </span><span class="si">{</span><span class="n">best_selected_r22</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Selected Features Polynomial Degree 1 Average R^2 score: 0.49
Selected Features Polynomial Degree 2 Average R^2 score: 0.54
Selected Features Polynomial Degree 3 Average R^2 score: 0.54
Selected Features Polynomial Degree 4 Average R^2 score: 0.54
Selected Features Polynomial Degree 5 Average R^2 score: -62715009326282743808.00
Best polynomial degree (Selected Features): 2 with R^2: 0.54
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate R² scores for polynomial degree 2 across folds for selected features</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_selected_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_selected</span><span class="p">)</span>
<span class="n">r2_scores_degree_2_folds</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_selected_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores_degree_2_folds</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">r2_scores_degree_2_folds</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">r2_scores_degree_2_folds</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">r2_scores_degree_2_folds</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Polynomial Degree 2 (Selected Features)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores_degree_2_folds</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/9050d21a8b1a26d426915dbdc1a7a3ba5a8130f46d4797610b3179311dbea9e2.png" src="../_images/9050d21a8b1a26d426915dbdc1a7a3ba5a8130f46d4797610b3179311dbea9e2.png" />
</div>
</div>
<section id="the-result-of-the-polynomial-regression-is-similar-and-does-not-improve-upon-the-original-polynomial-regression-model">
<h4>The result of the polynomial regression is similar and does not improve upon the original polynomial regression model.<a class="headerlink" href="#the-result-of-the-polynomial-regression-is-similar-and-does-not-improve-upon-the-original-polynomial-regression-model" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="models-with-regularization">
<h3>(5). Models with Regularization<a class="headerlink" href="#models-with-regularization" title="Link to this heading">#</a></h3>
<section id="since-the-models-with-selected-features-failed-to-provide-better-performance-i-will-try-using-ridge-regularization-to-identify-which-features-contribute-to-improving-predictions">
<h4>Since the models with selected features failed to provide better performance, I will try using Ridge regularization to identify which features contribute to improving predictions.<a class="headerlink" href="#since-the-models-with-selected-features-failed-to-provide-better-performance-i-will-try-using-ridge-regularization-to-identify-which-features-contribute-to-improving-predictions" title="Link to this heading">#</a></h4>
</section>
<section id="in-addition-to-plotting-the-ridge-regularization-i-also-included-an-extra-model-ridge-regression-although-we-did-not-cover-it-i-believe-it-will-be-useful-for-comparison">
<h4>In addition to plotting the Ridge regularization, I also included an extra model: Ridge Regression. Although we did not cover it, I believe it will be useful for comparison.<a class="headerlink" href="#in-addition-to-plotting-the-ridge-regularization-i-also-included-an-extra-model-ridge-regression-although-we-did-not-cover-it-i-believe-it-will-be-useful-for-comparison" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ridge Regularization Section</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="n">X_train_ridge</span><span class="p">,</span> <span class="n">X_test_ridge</span><span class="p">,</span> <span class="n">y_train_ridge</span><span class="p">,</span> <span class="n">y_test_ridge</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">),</span> <span class="n">X_train_ridge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">train_mse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alphas</span><span class="p">):</span>

    <span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_ridge</span><span class="p">,</span> <span class="n">y_train_ridge</span><span class="p">)</span>

    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_ridge</span><span class="p">)</span>
    <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_ridge</span><span class="p">)</span>

    <span class="n">train_mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train_ridge</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">))</span>
    <span class="n">test_mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_ridge</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">))</span>
    
    <span class="n">coefficients</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span>

<span class="n">min_test_error_alpha</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">coefficients</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">coefficients</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">min_test_error_alpha</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_xaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\alpha$ (Regularization strength)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Coefficients&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Ridge coefficients as a function of the regularization&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">&quot;Coefficients&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">best_coef</span> <span class="o">=</span> <span class="n">coefficients</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Coefficient at min_test_error_alpha: </span><span class="si">{</span><span class="n">best_coef</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">train_mse</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">alphas</span><span class="p">,</span> <span class="n">test_mse</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testing error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">min_test_error_alpha</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\alpha$ with min testing error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_xaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\alpha$ (Regularization strength)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Mean Squared Error&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Training and Testing Error as $\alpha$ Varies&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2a131850eb974029405c4f431b8f4a9d883a718b92f297e78bfcd102d1b97dd2.png" src="../_images/2a131850eb974029405c4f431b8f4a9d883a718b92f297e78bfcd102d1b97dd2.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Coefficient at min_test_error_alpha: [4754.89254546 -354.53094652  307.46418499 7115.69140237 2918.85897387
   30.01393196  846.59435371  441.47104729 2310.15681503 -494.19120566]
</pre></div>
</div>
<img alt="../_images/2afdff99fce71e0712f343afb81c8637098144eef8a71c670f08f2e6f5d5bb19.png" src="../_images/2afdff99fce71e0712f343afb81c8637098144eef8a71c670f08f2e6f5d5bb19.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ridge Regression</span>
<span class="n">X_train_ridge</span><span class="p">,</span> <span class="n">X_test_ridge</span><span class="p">,</span> <span class="n">y_train_ridge</span><span class="p">,</span> <span class="n">y_test_ridge</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">train_mse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_mse</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">coefficients</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">),</span> <span class="n">X_train_ridge</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alphas</span><span class="p">):</span>
    <span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_ridge</span><span class="p">,</span> <span class="n">y_train_ridge</span><span class="p">)</span>
    <span class="n">y_train_pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_ridge</span><span class="p">)</span>
    <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_ridge</span><span class="p">)</span>
    <span class="n">train_mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train_ridge</span><span class="p">,</span> <span class="n">y_train_pred</span><span class="p">))</span>
    <span class="n">test_mse</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test_ridge</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">))</span>
    <span class="n">coefficients</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span>

<span class="n">min_test_error_alpha</span> <span class="o">=</span> <span class="n">alphas</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">test_mse</span><span class="p">)]</span>
<span class="n">ridge_cv_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="n">min_test_error_alpha</span><span class="p">)</span>
    <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
    <span class="n">y_pred_fold</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_fold</span><span class="p">)</span>
    <span class="n">ridge_cv_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>

<span class="n">ridge_average_r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">ridge_cv_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average Ridge Regression R^2: </span><span class="si">{</span><span class="n">ridge_average_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Ridge Regression R^2: 0.62
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting R² scores for Ridge Regression with optimal alpha</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ridge_cv_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">ridge_cv_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">ridge_average_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">ridge_average_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Ridge Regression&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ridge_cv_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/66850cd5ff376e8cf4025d93e2238627e8100d0c3388c805df6cf60bf6aa3588.png" src="../_images/66850cd5ff376e8cf4025d93e2238627e8100d0c3388c805df6cf60bf6aa3588.png" />
</div>
</div>
</section>
<section id="the-r-2-of-ridge-regression-is-0-62-which-is-same-as-the-original-linear-regression-model">
<h4>The <span class="math notranslate nohighlight">\(R^2\)</span> of Ridge Regression is <strong>0.62</strong>, which is same as the original Linear Regression model.<a class="headerlink" href="#the-r-2-of-ridge-regression-is-0-62-which-is-same-as-the-original-linear-regression-model" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="new-selected-features">
<h3>New selected features<a class="headerlink" href="#new-selected-features" title="Link to this heading">#</a></h3>
<p>From the first plot above, we can identify the important features after applying regularization: ‘Age,’ ‘AnyTransplants,’ ‘AnyChronicDiseases,’ ‘HistoryOfCancerInFamily,’ ‘Weight,’ and ‘Height.’ I will use these features to train new models.</p>
<p>In the following models, I have selected the features:</p>
<ul class="simple">
<li><p><strong>Age</strong></p></li>
<li><p><strong>AnyTransplants</strong></p></li>
<li><p><strong>AnyChronicDiseases</strong></p></li>
<li><p><strong>HistoryOfCancerInFamily</strong></p></li>
<li><p><strong>Weight</strong></p></li>
<li><p><strong>Height</strong></p></li>
</ul>
<p>These features were chosen based on regularization analysis. By focusing on these features, the models might potentially achieve better predictive performance while reducing complexity.</p>
</section>
<section id="linear-regression-with-features-from-regularization-better-features">
<h3>(6). Linear Regression with features from regularization (better features).<a class="headerlink" href="#linear-regression-with-features-from-regularization-better-features" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_features_2</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;AnyTransplants&#39;</span><span class="p">,</span> <span class="s1">&#39;AnyChronicDiseases&#39;</span><span class="p">,</span> <span class="s1">&#39;HistoryOfCancerInFamily&#39;</span><span class="p">,</span> <span class="s1">&#39;Weight&#39;</span><span class="p">,</span> <span class="s1">&#39;Height&#39;</span><span class="p">]</span>
<span class="n">X_selected_2</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">selected_features_2</span><span class="p">]</span>

<span class="c1"># Linear Regression with features from regularization.¶</span>
<span class="n">linear_regression_selected_2</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores_selected_2</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression_selected_2</span><span class="p">,</span> <span class="n">X_selected_2</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="n">average_selected_2_r2</span> <span class="o">=</span> <span class="n">scores_selected_2</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average R² (Selected Features Model 2 - Better): </span><span class="si">{</span><span class="n">average_selected_2_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average R² (Selected Features Model 2 - Better): 0.61
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting R² scores for Selected Features Model 2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_selected_2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">scores_selected_2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">average_selected_2_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">average_selected_2_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Selected Features Model 2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_selected_2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2912af592e8c434772d070199263a9dbaa29f5ca83ffe559c2ba9c29611f31d4.png" src="../_images/2912af592e8c434772d070199263a9dbaa29f5ca83ffe559c2ba9c29611f31d4.png" />
</div>
</div>
<section id="the-r-2-did-not-improve-significantly-compared-to-the-original-model-but-it-is-better-than-the-model-with-the-originally-selected-features">
<h4>The <span class="math notranslate nohighlight">\(R^2\)</span> did not improve significantly compared to the original model, but it is better than the model with the originally selected features.<a class="headerlink" href="#the-r-2-did-not-improve-significantly-compared-to-the-original-model-but-it-is-better-than-the-model-with-the-originally-selected-features" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="polynomial-regression-with-features-from-regularization-better-features">
<h3>(7). Polynomial Regression with features from regularization (better features).<a class="headerlink" href="#polynomial-regression-with-features-from-regularization-better-features" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">selected_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">,</span> <span class="s1">&#39;AnyTransplants&#39;</span><span class="p">,</span> <span class="s1">&#39;AnyChronicDiseases&#39;</span><span class="p">,</span> <span class="s1">&#39;HistoryOfCancerInFamily&#39;</span><span class="p">,</span> <span class="s1">&#39;Weight&#39;</span><span class="p">,</span> <span class="s1">&#39;Height&#39;</span><span class="p">]</span>
<span class="n">X_selected</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">selected_features</span><span class="p">]</span>

<span class="n">scores_selected</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_selected</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average R^2 score (Selected Features No Polynomial): </span><span class="si">{</span><span class="n">scores_selected</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Polynomial for this new set of selected features</span>
<span class="n">best_selected_degree</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">best_selected_r2</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">degree</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="n">degree</span><span class="p">)</span>
    <span class="n">X_selected_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_selected</span><span class="p">)</span>
    <span class="n">scores_selected_poly</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_selected_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
    <span class="n">avg_selected_r2</span> <span class="o">=</span> <span class="n">scores_selected_poly</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Another Selected Features Polynomial Degree </span><span class="si">{</span><span class="n">degree</span><span class="si">}</span><span class="s1"> Average R^2 score: </span><span class="si">{</span><span class="n">avg_selected_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">avg_selected_r2</span> <span class="o">&gt;</span> <span class="n">best_selected_r2</span><span class="p">:</span>
        <span class="n">best_selected_r2</span> <span class="o">=</span> <span class="n">avg_selected_r2</span>
        <span class="n">best_selected_degree</span> <span class="o">=</span> <span class="n">degree</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Best polynomial degree (Another Selected Features): </span><span class="si">{</span><span class="n">best_selected_degree</span><span class="si">}</span><span class="s1"> with R^2: </span><span class="si">{</span><span class="n">best_selected_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average R^2 score (Selected Features No Polynomial): 0.61
Another Selected Features Polynomial Degree 1 Average R^2 score: 0.61
Another Selected Features Polynomial Degree 2 Average R^2 score: 0.67
Another Selected Features Polynomial Degree 3 Average R^2 score: -7371758434716592128.00
Another Selected Features Polynomial Degree 4 Average R^2 score: -346382196271761536.00
Another Selected Features Polynomial Degree 5 Average R^2 score: -12089905827124340736.00
Best polynomial degree (Another Selected Features): 2 with R^2: 0.67
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate R² scores for polynomial degree 2 across folds</span>
<span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_selected_poly</span> <span class="o">=</span> <span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_selected</span><span class="p">)</span>
<span class="n">r2_scores_degree_2_folds</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">linear_regression</span><span class="p">,</span> <span class="n">X_selected_poly</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>

<span class="c1"># Plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores_degree_2_folds</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">r2_scores_degree_2_folds</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">r2_scores_degree_2_folds</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">r2_scores_degree_2_folds</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;R² Scores for Polynomial Degree 2 Across Folds&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r2_scores_degree_2_folds</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/876df92336f45234503d0cb5a1ce481674a331bc0d1a0640e05b9bcb82251cef.png" src="../_images/876df92336f45234503d0cb5a1ce481674a331bc0d1a0640e05b9bcb82251cef.png" />
</div>
</div>
<section id="so-far-this-model-gives-the-highest-performance-which-r-2-of-0-67">
<h4>So far this model gives the highest performance, which <span class="math notranslate nohighlight">\(R^2\)</span> of <strong>0.67</strong>.<a class="headerlink" href="#so-far-this-model-gives-the-highest-performance-which-r-2-of-0-67" title="Link to this heading">#</a></h4>
</section>
</section>
</section>
<hr class="docutils" />
<section id="extras">
<h2>4.5 Extras<a class="headerlink" href="#extras" title="Link to this heading">#</a></h2>
<section id="in-this-section-i-will-introduce-a-few-additional-models-that-were-not-covered-in-our-class-these-models-all-demonstrate-good-performance">
<h3>In this section, I will introduce a few additional models that were not covered in our class. These models all demonstrate good performance.<a class="headerlink" href="#in-this-section-i-will-introduce-a-few-additional-models-that-were-not-covered-in-our-class-these-models-all-demonstrate-good-performance" title="Link to this heading">#</a></h3>
</section>
<section id="random-forest-model">
<h3>(8). Random Forest Model<a class="headerlink" href="#random-forest-model" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Random Forest Model</span>
<span class="n">rf_regressor</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">scores_rf</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf_regressor</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;r2&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average Random Forest R^2: </span><span class="si">{</span><span class="n">scores_rf</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Random Forest R^2: 0.79
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting R² scores for Random Forest Regressor</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_rf</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">scores_rf</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">scores_rf</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">scores_rf</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Random Forest Regressor&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores_rf</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c6f517ddd2a80c06a1e3180f09b0c1dc19c30738d47b691d6bd618336e3de165.png" src="../_images/c6f517ddd2a80c06a1e3180f09b0c1dc19c30738d47b691d6bd618336e3de165.png" />
</div>
</div>
<section id="the-r-2-of-this-model-is-0-79">
<h4>The <span class="math notranslate nohighlight">\(R^2\)</span> of this model is <strong>0.79</strong>.<a class="headerlink" href="#the-r-2-of-this-model-is-0-79" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="gradient-boosting">
<h3>(9). Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Gradient Boosting¶</span>
<span class="n">gbr</span> <span class="o">=</span> <span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
                                <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">gbr_r2_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">gbr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
    <span class="n">y_pred_fold</span> <span class="o">=</span> <span class="n">gbr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_fold</span><span class="p">)</span>
    <span class="n">gbr_r2_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>
<span class="n">average_gbr_r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">gbr_r2_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average Gradient Boosting R^2: </span><span class="si">{</span><span class="n">average_gbr_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Gradient Boosting R^2: 0.77
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting Gradient Boosting R² scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">gbr_r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">gbr_r2_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Gradient Boosting R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">average_gbr_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">average_gbr_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Gradient Boosting&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">gbr_r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/cd865fc61f2aff2d0a8864fed8793f75868ebd32f487ff645df605c85e37e0b9.png" src="../_images/cd865fc61f2aff2d0a8864fed8793f75868ebd32f487ff645df605c85e37e0b9.png" />
</div>
</div>
<section id="although-gradient-boosting-did-not-achieve-a-higher-r-2-than-random-forest-it-still-outperforms-the-standard-regression-models">
<h4>Although Gradient Boosting did not achieve a higher <span class="math notranslate nohighlight">\(R^2\)</span> than Random Forest, it still outperforms the standard regression models.<a class="headerlink" href="#although-gradient-boosting-did-not-achieve-a-higher-r-2-than-random-forest-it-still-outperforms-the-standard-regression-models" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="hist-gradient-boosting">
<h3>(10). Hist Gradient Boosting<a class="headerlink" href="#hist-gradient-boosting" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Hist Gradient Boosting</span>
<span class="n">hgb</span> <span class="o">=</span> <span class="n">HistGradientBoostingRegressor</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> 
                                    <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="mi">31</span><span class="p">,</span> 
                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">hgb_r2_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">hgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
    <span class="n">y_pred_fold</span> <span class="o">=</span> <span class="n">hgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_fold</span><span class="p">)</span>
    <span class="n">hgb_r2_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>
<span class="n">average_hgb_r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hgb_r2_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average HistGradientBoosting R^2: </span><span class="si">{</span><span class="n">average_hgb_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average HistGradientBoosting R^2: 0.78
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting HistGradientBoosting R² scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hgb_r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">hgb_r2_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;HistGradientBoosting R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">average_hgb_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">average_hgb_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for HistGradientBoosting&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hgb_r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/157c3cd079f2f916713a2b78a1b84863f999697e39a8fd501be7588376221327.png" src="../_images/157c3cd079f2f916713a2b78a1b84863f999697e39a8fd501be7588376221327.png" />
</div>
</div>
<section id="the-r-2-is-higher-than-gradient-boosting">
<h4>The <span class="math notranslate nohighlight">\(R^2\)</span> is higher than Gradient Boosting.<a class="headerlink" href="#the-r-2-is-higher-than-gradient-boosting" title="Link to this heading">#</a></h4>
</section>
</section>
<hr class="docutils" />
<section id="stacking-regressor">
<h3>(11). Stacking Regressor<a class="headerlink" href="#stacking-regressor" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Stacking Regressor</span>
<span class="n">stacking_model</span> <span class="o">=</span> <span class="n">StackingRegressor</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">&#39;random_forest&#39;</span><span class="p">,</span> <span class="n">rf_regressor</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">&#39;hist_gradient_boosting&#39;</span><span class="p">,</span> <span class="n">hgb</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">final_estimator</span><span class="o">=</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">stacking_r2_scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="n">X_train_fold</span><span class="p">,</span> <span class="n">X_test_fold</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">y_train_fold</span><span class="p">,</span> <span class="n">y_test_fold</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
    <span class="n">stacking_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_fold</span><span class="p">,</span> <span class="n">y_train_fold</span><span class="p">)</span>
    <span class="n">y_pred_fold</span> <span class="o">=</span> <span class="n">stacking_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_fold</span><span class="p">)</span>
    <span class="n">r2</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test_fold</span><span class="p">,</span> <span class="n">y_pred_fold</span><span class="p">)</span>
    <span class="n">stacking_r2_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">r2</span><span class="p">)</span>

<span class="n">average_stacking_r2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">stacking_r2_scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Average Stacking Regressor R^2: </span><span class="si">{</span><span class="n">average_stacking_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average Stacking Regressor R^2: 0.80
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plotting Stacking Regressor R² scores</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stacking_r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">stacking_r2_scores</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Stacking Regressor R² per Fold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">average_stacking_r2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Average R²: </span><span class="si">{</span><span class="n">average_stacking_r2</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Cross-Validation R² Scores for Stacking Regressor&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Fold Number&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;R² Score&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">stacking_r2_scores</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/c222c08f3a1f7871e8d16d10150fbd930ee793634dc44d3e2eba25fdf3156ae7.png" src="../_images/c222c08f3a1f7871e8d16d10150fbd930ee793634dc44d3e2eba25fdf3156ae7.png" />
</div>
</div>
<section id="stacking-regressor-gives-the-best-performance-with-r-2-of-0-8">
<h4>Stacking Regressor gives the best performance, with <span class="math notranslate nohighlight">\(R^2\)</span> of <strong>0.8</strong>.<a class="headerlink" href="#stacking-regressor-gives-the-best-performance-with-r-2-of-0-8" title="Link to this heading">#</a></h4>
</section>
</section>
</section>
<hr class="docutils" />
<section id="analysis">
<h2>5. Analysis<a class="headerlink" href="#analysis" title="Link to this heading">#</a></h2>
<section id="performance-comparing">
<h3>Performance Comparing<a class="headerlink" href="#performance-comparing" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ChatGPT contributed a lot to this section.</span>
<span class="n">model_scores</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Linear Regression&#39;</span><span class="p">:</span> <span class="n">average_r2</span><span class="p">,</span>
    <span class="s1">&#39;Poly Reg (All Features)&#39;</span><span class="p">:</span> <span class="n">best_r2</span><span class="p">,</span>
    <span class="s1">&#39;Poly Reg (Selected Features)&#39;</span><span class="p">:</span> <span class="n">best_selected_r22</span><span class="p">,</span>  <span class="c1"># Existing model</span>
    <span class="s1">&#39;Ridge Regression&#39;</span><span class="p">:</span> <span class="n">ridge_average_r2</span><span class="p">,</span>
    <span class="s1">&#39;Random Forest&#39;</span><span class="p">:</span> <span class="n">scores_rf</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span>
    <span class="s1">&#39;Gradient Boosting&#39;</span><span class="p">:</span> <span class="n">average_gbr_r2</span><span class="p">,</span>
    <span class="s1">&#39;HistGradientBoosting&#39;</span><span class="p">:</span> <span class="n">average_hgb_r2</span><span class="p">,</span>
    <span class="s1">&#39;Stacking Regressor&#39;</span><span class="p">:</span> <span class="n">average_stacking_r2</span><span class="p">,</span>
    <span class="s1">&#39;Selected Features Model 1&#39;</span><span class="p">:</span> <span class="n">average_selected_1_r2</span><span class="p">,</span>
    <span class="s1">&#39;Selected Features Model 2 (Better)&#39;</span><span class="p">:</span> <span class="n">average_selected_2_r2</span>
<span class="p">}</span>

<span class="c1"># -----------------------------------</span>
<span class="c1"># Step 1: Add the New Polynomial Regression (Selected Features) Model</span>
<span class="c1"># -----------------------------------</span>

<span class="c1"># Define a unique name for the new model to avoid confusion</span>
<span class="n">new_model_name</span> <span class="o">=</span> <span class="s1">&#39;Poly Reg (Selected Features v2)&#39;</span>

<span class="c1"># Assign the new R² score to the new model name</span>
<span class="n">model_scores</span><span class="p">[</span><span class="n">new_model_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_selected_r2</span>

<span class="c1"># -----------------------------------</span>
<span class="c1"># Step 2: Plot All 11 Models</span>
<span class="c1"># -----------------------------------</span>

<span class="c1"># Sort models by R² in descending order</span>
<span class="n">sorted_models</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">model_scores</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">models</span><span class="p">,</span> <span class="n">r2_values</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">sorted_models</span><span class="p">)</span>

<span class="c1"># Determine y-axis limits with a margin</span>
<span class="n">y_min</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">r2_values</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.05</span> <span class="k">if</span> <span class="nb">min</span><span class="p">(</span><span class="n">r2_values</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
<span class="n">y_max</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">r2_values</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.05</span>

<span class="c1"># Apply a clean Matplotlib style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>  <span class="c1"># Alternatives: &#39;fivethirtyeight&#39;, &#39;classic&#39;, etc.</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>  <span class="c1"># Increased size for better readability with more models</span>

<span class="c1"># Create a color palette based on R² values</span>
<span class="n">normalized_r2</span> <span class="o">=</span> <span class="p">[</span><span class="n">val</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="n">r2_values</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">r2_values</span><span class="p">]</span>
<span class="n">bars</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">models</span><span class="p">,</span> <span class="n">r2_values</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">(</span><span class="n">normalized_r2</span><span class="p">),</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>

<span class="c1"># Annotate bars with R² values</span>
<span class="k">for</span> <span class="n">bar</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">bars</span><span class="p">,</span> <span class="n">r2_values</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
        <span class="n">bar</span><span class="o">.</span><span class="n">get_x</span><span class="p">()</span> <span class="o">+</span> <span class="n">bar</span><span class="o">.</span><span class="n">get_width</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> 
        <span class="n">score</span> <span class="o">+</span> <span class="mf">0.01</span><span class="p">,</span>  <span class="c1"># Slightly above the bar</span>
        <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> 
        <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> 
        <span class="n">va</span><span class="o">=</span><span class="s1">&#39;bottom&#39;</span><span class="p">,</span> 
        <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span> 
        <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span>
        <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span>
    <span class="p">)</span>

<span class="c1"># Customize axes and title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="mi">45</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Average R² Score&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Comparison of Average R² Scores Across Models&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>

<span class="c1"># Remove unnecessary spines for a cleaner look</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;top&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">&#39;right&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Add subtle gridlines</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>

<span class="c1"># Adjust layout to prevent clipping of tick-labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Display the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b99f5f00ea678006b760091cce732e838018fedd55ce9a4cf0c9a626104c9a5f.png" src="../_images/b99f5f00ea678006b760091cce732e838018fedd55ce9a4cf0c9a626104c9a5f.png" />
</div>
</div>
</section>
<section id="from-the-histogram-plot-we-can-observe-a-clearer-representation-of-prediction-performance-the-additional-models-show-similar-results-while-the-other-models-perform-adequately-among-all-the-models-discussed-in-our-lecture-polynomial-regression-models-of-degree-2-provide-the-best-predictions-both-with-and-without-the-selected-features">
<h3>From the histogram plot, we can observe a clearer representation of prediction performance. The additional models show similar results, while the other models perform adequately. Among all the models discussed in our lecture, polynomial regression models of degree 2 provide the best predictions, both with and without the selected features.<a class="headerlink" href="#from-the-histogram-plot-we-can-observe-a-clearer-representation-of-prediction-performance-the-additional-models-show-similar-results-while-the-other-models-perform-adequately-among-all-the-models-discussed-in-our-lecture-polynomial-regression-models-of-degree-2-provide-the-best-predictions-both-with-and-without-the-selected-features" title="Link to this heading">#</a></h3>
</section>
<section id="comparing-regular-and-advanced-models">
<h3>Comparing Regular and Advanced Models<a class="headerlink" href="#comparing-regular-and-advanced-models" title="Link to this heading">#</a></h3>
<p>Both regular and advanced models perform well, but there’s a noticeable gap between them. Let’s explore why advanced models often have the edge.</p>
</section>
<hr class="docutils" />
<section id="ensemble-methods-the-power-behind-advanced-models">
<h3>Ensemble Methods: The Power Behind Advanced Models<a class="headerlink" href="#ensemble-methods-the-power-behind-advanced-models" title="Link to this heading">#</a></h3>
<p>Advanced models often use <strong>Ensemble Methods</strong>, which combine multiple models to capture complex patterns in data. Unlike simpler models, they don’t assume linear relationships and can handle intricate, non-linear interactions directly from the data.</p>
</section>
<hr class="docutils" />
<section id="random-forest">
<h3>Random Forest<a class="headerlink" href="#random-forest" title="Link to this heading">#</a></h3>
<p>A <strong>Random Forest</strong> combines many decision trees to improve accuracy and reliability.</p>
<p><strong>How It Works:</strong></p>
<ul class="simple">
<li><p><strong>Multiple Trees:</strong> Imagine a group of friends each making their own prediction (e.g., weather forecasts) using different information.</p></li>
<li><p><strong>Averaging Predictions:</strong> By averaging all their guesses, the overall prediction becomes more accurate than any single friend’s guess.</p></li>
<li><p><strong>Benefit:</strong> Reduces errors by averaging out the variance from individual trees.</p></li>
</ul>
<p><strong>Result:</strong> A robust model that generalizes well by leveraging the diversity of multiple trees.</p>
</section>
<hr class="docutils" />
<section id="id1">
<h3>Gradient Boosting<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p><strong>Gradient Boosting</strong> builds models step-by-step, each one correcting the errors of the previous ones.</p>
<p><strong>How It Works:</strong></p>
<ol class="arabic simple">
<li><p><strong>Start Simple:</strong> Begin with a basic model.</p></li>
<li><p><strong>Identify Errors:</strong> Find where this model is wrong.</p></li>
<li><p><strong>Add Correctors:</strong> Introduce new models that fix these mistakes.</p></li>
<li><p><strong>Iterate:</strong> Repeat the process to continuously improve accuracy.</p></li>
</ol>
<p><strong>HistGradientBoosting:</strong> A faster variant that uses histograms to speed up training without sacrificing performance.</p>
<p><strong>Result:</strong> Highly accurate models that refine themselves iteratively to capture complex data patterns.</p>
</section>
<hr class="docutils" />
<section id="stacking">
<h3>Stacking<a class="headerlink" href="#stacking" title="Link to this heading">#</a></h3>
<p><strong>Stacking</strong> combines different models to leverage their unique strengths.</p>
<p><strong>How It Works:</strong></p>
<ul class="simple">
<li><p><strong>Base Models:</strong> Train multiple models (e.g., Random Forest, Gradient Boosting).</p></li>
<li><p><strong>Meta-Model:</strong> Use another model to learn how to best combine the predictions from the base models.</p></li>
</ul>
<p><strong>Benefit:</strong> Often achieves better performance by integrating diverse perspectives from different models.</p>
<p><strong>Result:</strong> A unified model that outperforms any single base model by smartly combining their predictions.</p>
</section>
<hr class="docutils" />
<section id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Random Forest:</strong> Aggregates multiple decision trees to enhance accuracy and reduce overfitting.</p></li>
<li><p><strong>Gradient Boosting:</strong> Builds models sequentially, each improving on the last to achieve high precision.</p></li>
<li><p><strong>Stacking:</strong> Combines various models to capitalize on their individual strengths for superior performance.</p></li>
</ul>
<p>These ensemble techniques are powerful because they merge the capabilities of several models, making them more effective for complex tasks.</p>
</section>
</section>
<section id="conclusion">
<h2>6. Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<section id="this-project-focused-on-a-few-key-steps">
<h3>This project focused on a few key steps:<a class="headerlink" href="#this-project-focused-on-a-few-key-steps" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Data Preparation</strong>: Standardized and scaled the data to ensure it was ready for modeling.</p></li>
<li><p><strong>Visualization</strong>: Created plots to understand data distributions and feature relationships, often using ChatGPT’s help for refining them.</p></li>
<li><p><strong>Modeling</strong>: Compared normal regression methods to more advanced techniques, while incorporating k-fold cross-validation to validate the results.</p></li>
</ul>
</section>
<section id="key-takeaways">
<h3>Key Takeaways:<a class="headerlink" href="#key-takeaways" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Model Performance</strong>: R² was the main metric used, showing how well the models explained the target variable.</p></li>
<li><p><strong>Advanced Techniques</strong>: Extra regression methods provided better insights into the data’s complexity compared to standard approaches.</p></li>
<li><p><strong>Collaborative Tools</strong>: ChatGPT was a helpful resource, especially for plotting and integrating k-fold cross-validation into the workflow.</p></li>
</ul>
</section>
<section id="future-improvements">
<h3>Future Improvements:<a class="headerlink" href="#future-improvements" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Fine-tune model settings to improve results further.</p></li>
<li><p>Explore adding new features or data to make the predictions even more reliable.</p></li>
</ul>
</section>
<section id="some-final-thoughts">
<h3>Some final thoughts:<a class="headerlink" href="#some-final-thoughts" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>1</strong>. I mostly used <span class="math notranslate nohighlight">\(R^2\)</span> because it’s straightforward and does a good job of showing how well the model explains the variance in the target variable. It felt like the right choice given the type of analysis I was doing.</p></li>
<li><p><strong>2</strong>. I didn’t bother with Lasso regression since Ridge already gave me what I needed. Ridge retains all the features, which was helpful for understanding how each one contributed without completely dropping any of them.</p></li>
<li><p><strong>3</strong>. I gave machine learning models a try, but the results weren’t much better than the simpler regression models. Considering the extra complexity they add, I decided it wasn’t worth including them here.</p></li>
<li><p><strong>4</strong>. I didn’t include any classification models because this project was focused on predicting a continuous value (premium price). Classification just didn’t fit with the goals I had in mind.</p></li>
</ul>
<p>That said, there’s definitely room to explore more approaches in the future, especially with a larger or more complex dataset.</p>
</section>
</section>
<section id="references">
<h2>7. References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<p>This project wouldn’t have been possible without the guidance, inspiration, and resources provided by the following:</p>
<ul class="simple">
<li><p><strong>Course Notes</strong>: <a class="reference external" href="https://rayzhangzirui.github.io/math10sp24/notes/notes_intro.html">Introduction to Mathematical Concepts</a><br />
These notes laid the foundation for understanding the mathematical principles applied in this project.</p></li>
<li><p><strong>Dataset</strong>: <a class="reference external" href="https://www.kaggle.com/datasets/tejashvi14/medical-insurance-premium-prediction">Medical Insurance Premium Prediction Dataset</a> (Kaggle)<br />
I am grateful for the open data shared by the community, which made this analysis possible.</p></li>
<li><p><strong>ChatGPT</strong>: Assisted in brainstorming ideas, refining code, debugging issues, and improving clarity in explanations and visualizations.</p></li>
<li><p><strong>Wikipedia</strong>: Regression models, machine learning algorithms, and cross-validation techniques.</p></li>
<li><p><strong>Documentation</strong>: <a class="reference external" href="https://scikit-learn.org/stable/">Scikit-learn: Machine Learning in Python</a> , <a class="reference external" href="https://matplotlib.org/">Matplotlib: Visualization Library</a> , <a class="reference external" href="https://seaborn.pydata.org/">Seaborn: Statistical Data Visualization</a> and more.</p></li>
<li><p><strong>My Instructors and Peers</strong>: Their guidance and encouragement throughout the learning process were invaluable.</p></li>
</ul>
<p>This project reflects not just my efforts but also the collective knowledge and support of a broader community. I recognize that there is always more to learn and am deeply thankful for these resources that have made my work possible.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./final_projects"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Pinge_Chen.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Predicting Subscription to Term Deposit</p>
      </div>
    </a>
    <a class="right-next"
       href="Zhang_Zhang.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Prediction of High School Students’ Academic Performance</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Medical Insurance Prediction</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#import-libraries">0. Import Libraries</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-the-dataset">1. Introduction to the Dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preprocessing">2. Data Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-code-below-provides-information-about-the-dataset-key-points-to-note-include">The code below provides information about the dataset. Key points to note include:</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-scaling">Feature Scaling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploratory-data-analysis">3. Exploratory Data Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-observations">Some observations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#from-the-correlation-heatmap-we-can-observe-that-the-most-valuable-insights-come-from-the-last-row-which-shows-the-correlation-between-premium-price-and-other-features-the-correlation-between-age-and-premium-price-has-the-highest-value-which-is-expected-the-next-most-correlated-feature-is-the-number-of-major-surgeries-with-a-correlation-of-0-43-based-on-these-statistics-we-can-create-a-subset-of-features-to-train-the-models">From the correlation heatmap, we can observe that the most valuable insights come from the last row, which shows the correlation between Premium Price and other features. The correlation between Age and Premium Price has the highest value, which is expected. The next most correlated feature is the Number of Major Surgeries, with a correlation of <strong>0.43</strong>. Based on these statistics, we can create a subset of features to train the models.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">4. Model Selection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-model">(1). Linear Regression Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#from-the-result-we-can-see-the-average-r-2-with-5-fold-cross-validation-is-around-0-62">From the result, we can see the average <span class="math notranslate nohighlight">\(R^2\)</span> with 5-fold cross-validation is around <strong>0.62</strong>.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression-model">(2). Polynomial Regression Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-highest-r-2-with-cross-validation-is-degree-of-2-polynomial-with-r-2-of-0-67-other-degrees-are-really-off">The highest <span class="math notranslate nohighlight">\(R^2\)</span> with cross-validation is degree of 2 polynomial, with R^2 of <strong>0.67</strong>. Other degrees are really off.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-selection-for-the-next-two-models">Feature Selection for the Next Two Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-selected-features">(3). Linear Regression with Selected Features</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-score-is-0-49-which-is-lower-than-that-of-linear-regression-without-the-selected-features-this-indicates-that-the-features-i-selected-do-not-improve-the-performance-of-the-linear-regression-model">The <span class="math notranslate nohighlight">\(R^2\)</span> score is <strong>0.49</strong>, which is lower than that of Linear Regression without the selected features. This indicates that the features I selected do not improve the performance of the Linear Regression model.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression-with-selected-features">(4). Polynomial Regression with Selected Features</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-result-of-the-polynomial-regression-is-similar-and-does-not-improve-upon-the-original-polynomial-regression-model">The result of the polynomial regression is similar and does not improve upon the original polynomial regression model.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#models-with-regularization">(5). Models with Regularization</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#since-the-models-with-selected-features-failed-to-provide-better-performance-i-will-try-using-ridge-regularization-to-identify-which-features-contribute-to-improving-predictions">Since the models with selected features failed to provide better performance, I will try using Ridge regularization to identify which features contribute to improving predictions.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#in-addition-to-plotting-the-ridge-regularization-i-also-included-an-extra-model-ridge-regression-although-we-did-not-cover-it-i-believe-it-will-be-useful-for-comparison">In addition to plotting the Ridge regularization, I also included an extra model: Ridge Regression. Although we did not cover it, I believe it will be useful for comparison.</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-of-ridge-regression-is-0-62-which-is-same-as-the-original-linear-regression-model">The <span class="math notranslate nohighlight">\(R^2\)</span> of Ridge Regression is <strong>0.62</strong>, which is same as the original Linear Regression model.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#new-selected-features">New selected features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-features-from-regularization-better-features">(6). Linear Regression with features from regularization (better features).</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-did-not-improve-significantly-compared-to-the-original-model-but-it-is-better-than-the-model-with-the-originally-selected-features">The <span class="math notranslate nohighlight">\(R^2\)</span> did not improve significantly compared to the original model, but it is better than the model with the originally selected features.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#polynomial-regression-with-features-from-regularization-better-features">(7). Polynomial Regression with features from regularization (better features).</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#so-far-this-model-gives-the-highest-performance-which-r-2-of-0-67">So far this model gives the highest performance, which <span class="math notranslate nohighlight">\(R^2\)</span> of <strong>0.67</strong>.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#extras">4.5 Extras</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#in-this-section-i-will-introduce-a-few-additional-models-that-were-not-covered-in-our-class-these-models-all-demonstrate-good-performance">In this section, I will introduce a few additional models that were not covered in our class. These models all demonstrate good performance.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest-model">(8). Random Forest Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-of-this-model-is-0-79">The <span class="math notranslate nohighlight">\(R^2\)</span> of this model is <strong>0.79</strong>.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting">(9). Gradient Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#although-gradient-boosting-did-not-achieve-a-higher-r-2-than-random-forest-it-still-outperforms-the-standard-regression-models">Although Gradient Boosting did not achieve a higher <span class="math notranslate nohighlight">\(R^2\)</span> than Random Forest, it still outperforms the standard regression models.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hist-gradient-boosting">(10). Hist Gradient Boosting</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-r-2-is-higher-than-gradient-boosting">The <span class="math notranslate nohighlight">\(R^2\)</span> is higher than Gradient Boosting.</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking-regressor">(11). Stacking Regressor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking-regressor-gives-the-best-performance-with-r-2-of-0-8">Stacking Regressor gives the best performance, with <span class="math notranslate nohighlight">\(R^2\)</span> of <strong>0.8</strong>.</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#analysis">5. Analysis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-comparing">Performance Comparing</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#from-the-histogram-plot-we-can-observe-a-clearer-representation-of-prediction-performance-the-additional-models-show-similar-results-while-the-other-models-perform-adequately-among-all-the-models-discussed-in-our-lecture-polynomial-regression-models-of-degree-2-provide-the-best-predictions-both-with-and-without-the-selected-features">From the histogram plot, we can observe a clearer representation of prediction performance. The additional models show similar results, while the other models perform adequately. Among all the models discussed in our lecture, polynomial regression models of degree 2 provide the best predictions, both with and without the selected features.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparing-regular-and-advanced-models">Comparing Regular and Advanced Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-methods-the-power-behind-advanced-models">Ensemble Methods: The Power Behind Advanced Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forest">Random Forest</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Gradient Boosting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking">Stacking</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">6. Conclusion</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#this-project-focused-on-a-few-key-steps">This project focused on a few key steps:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#future-improvements">Future Improvements:</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#some-final-thoughts">Some final thoughts:</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">7. References</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Ray Zirui Zhang
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>